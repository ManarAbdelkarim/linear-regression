{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python394jvsc74a57bd007bb041272e27afd7d0da05217cb793136ac5ea2a273a164262c068e828f2281",
   "display_name": "Python 3.9.4 64-bit ('.venv': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "07bb041272e27afd7d0da05217cb793136ac5ea2a273a164262c068e828f2281"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Sentiment Analyzer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sentence    Wow... Loved this place.\nlabel                              1\nsource                          yelp\nName: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "filepath_dict2 = {'yelp':   'data/yelp_labelled.txt',\n",
    "                 'amazon': 'data/amazon_cells_labelled.txt',\n",
    "                 'imdb':   'data/imdb_labelled.txt'}\n",
    "# filepath_dict = {'profanity-check':'data/clean_data.txt'}\n",
    "\n",
    "df_list = []\n",
    "for source, filepath in filepath_dict2.items():\n",
    "    df = pd.read_csv(filepath, names=['sentence', 'label'], sep='\\t')\n",
    "    df['source'] = source  \n",
    "    df_list.append(df)\n",
    "# for source, filepath in filepath_dict.items():\n",
    "#     df = pd.read_csv(filepath, names=['label', 'sentence'], sep=',')\n",
    "#     df['source'] = source  \n",
    "#     df_list.append(df)\n",
    "\n",
    "\n",
    "df = pd.concat(df_list)\n",
    "print(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['John likes ice cream', 'John hates chocolate.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'John': 0, 'likes': 5, 'ice': 4, 'cream': 2, 'hates': 3, 'chocolate': 1}"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=0, lowercase=False )\n",
    "vectorizer.fit(sentences)\n",
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = vectorizer.transform(sentences).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0, 1, 1],\n",
       "       [1, 1, 0, 1, 0, 0]])"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['sentence'].values\n",
    "y = df['label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "   X, y, test_size=0.25, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([\"I'd rather eat airline food, seriously.\",\n",
       "       'There was a warm feeling with the service and I felt like their guest for a special treat.',\n",
       "       'Fantastic earphones.', ..., 'The lead man is charisma-free.  ',\n",
       "       'Not good for the money.', 'Horrible phone.'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<2061x4506 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 23280 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "X_train = vectorizer.transform(X_train)\n",
    "X_test  = vectorizer.transform(X_test)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<46089x160696 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1765938 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "source": [
    "1714 words available\n",
    "each sentence uses some of them\n",
    "sentence = [0,0,0,0,1,0,0,0,1,0,0......]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.8195050946142649\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "score = classifier.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                 sentence label  \\\n",
       "0                             Wow... Loved this place.\\t1   NaN   \n",
       "1                                   Crust is not good.\\t0   NaN   \n",
       "2            Not tasty and the texture was just nasty.\\t0   NaN   \n",
       "3       Stopped by during the late May bank holiday of...   NaN   \n",
       "4       The selection on the menu was great and so wer...   NaN   \n",
       "...                                                   ...   ...   \n",
       "184349                   Template:uw-vandalism2 >  | Talk     0   \n",
       "184350   Regrets are for pussies. Shit happens, deal w...     1   \n",
       "184351  Could this possibly be the origin of popular g...     0   \n",
       "184352  \"Your article submission has been declined, an...     0   \n",
       "184353  .\\nEditors can not move articles except inside...     0   \n",
       "\n",
       "                 source  \n",
       "0                  yelp  \n",
       "1                  yelp  \n",
       "2                  yelp  \n",
       "3                  yelp  \n",
       "4                  yelp  \n",
       "...                 ...  \n",
       "184349  profanity-check  \n",
       "184350  profanity-check  \n",
       "184351  profanity-check  \n",
       "184352  profanity-check  \n",
       "184353  profanity-check  \n",
       "\n",
       "[187091 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>label</th>\n      <th>source</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Wow... Loved this place.\\t1</td>\n      <td>NaN</td>\n      <td>yelp</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Crust is not good.\\t0</td>\n      <td>NaN</td>\n      <td>yelp</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Not tasty and the texture was just nasty.\\t0</td>\n      <td>NaN</td>\n      <td>yelp</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Stopped by during the late May bank holiday of...</td>\n      <td>NaN</td>\n      <td>yelp</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The selection on the menu was great and so wer...</td>\n      <td>NaN</td>\n      <td>yelp</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>184349</th>\n      <td>Template:uw-vandalism2 &gt;  | Talk</td>\n      <td>0</td>\n      <td>profanity-check</td>\n    </tr>\n    <tr>\n      <th>184350</th>\n      <td>Regrets are for pussies. Shit happens, deal w...</td>\n      <td>1</td>\n      <td>profanity-check</td>\n    </tr>\n    <tr>\n      <th>184351</th>\n      <td>Could this possibly be the origin of popular g...</td>\n      <td>0</td>\n      <td>profanity-check</td>\n    </tr>\n    <tr>\n      <th>184352</th>\n      <td>\"Your article submission has been declined, an...</td>\n      <td>0</td>\n      <td>profanity-check</td>\n    </tr>\n    <tr>\n      <th>184353</th>\n      <td>.\\nEditors can not move articles except inside...</td>\n      <td>0</td>\n      <td>profanity-check</td>\n    </tr>\n  </tbody>\n</table>\n<p>187091 rows Ã— 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Altranativally , I can loop \n",
    "# for source in df['source'].unique():\n",
    "#     df_source = df[df['source'] == source]\n",
    "#     sentences = df_source['sentence'].values\n",
    "#     y = df_source['label'].values\n",
    "\n",
    "#     sentences_train, sentences_test, y_train, y_test = train_test_split(\n",
    "#         sentences, y, test_size=0.25, random_state=1000)\n",
    "\n",
    "#     vectorizer = CountVectorizer()\n",
    "#     vectorizer.fit(sentences_train)\n",
    "#     X_train = vectorizer.transform(sentences_train)\n",
    "#     X_test  = vectorizer.transform(sentences_test)\n",
    "\n",
    "#     classifier = LogisticRegression()\n",
    "#     classifier.fit(X_train, y_train)\n",
    "#     score = classifier.score(X_test, y_test)\n",
    "#     print('Accuracy for {} data: {:.4f}'.format(source, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy  data: 0.8195\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "score = classifier.score(X_test, y_test)\n",
    "print('Accuracy  data: {:.4f}'.format( score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'My_sentences' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-95db868484a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMy_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{sentence[i]} is a good feedback'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'My_sentences' is not defined"
     ]
    }
   ],
   "source": [
    "vectorizer.transform(sentences).toarray()\n",
    "predict=classifier.predict(My_sentences)\n",
    "for i in range(len(predict)) :\n",
    "    if predict[i] == 1:\n",
    "        print(f'{sentence[i]} is a good feedback')\n",
    "    else:\n",
    "        print(f'{sentence[i]} is a bad feedback')\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}